"""
Integration test for wired portfolio optimization system.

Tests the complete flow from database to recommendations.
"""

import asyncio
import logging
from datetime import date

import numpy as np

from app.ai.optimization import PortfolioOptimizer
from app.ai.decision_engine import DecisionEngine
from app.ai.profile import RiskProfile
from app.ai.llm_explainer import LLMConfig

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


async def test_optimization_pipeline():
    """Test the complete optimization pipeline with synthetic data."""
    
    logger.info("=" * 70)
    logger.info("Portfolio Optimization & Decision Engine - Integration Test")
    logger.info("=" * 70)
    
    # Test data
    symbols = ["BNA", "STB", "BIAT", "SOTUMAG", "SOTRAPIL"]
    num_symbols = len(symbols)
    lookback_days = 250
    
    # Generate synthetic returns (would come from database)
    logger.info(f"\n1. Generating synthetic data for {num_symbols} symbols...")
    rng = np.random.default_rng(42)
    returns = rng.normal(0.001, 0.02, (lookback_days, num_symbols))
    market_returns = rng.normal(0.0008, 0.015, lookback_days)
    
    logger.info(f"   Returns matrix shape: {returns.shape}")
    logger.info(f"   Market returns shape: {market_returns.shape}")
    
    # Test 1: Portfolio Optimization
    logger.info("\n2. Running Portfolio Optimization...")
    logger.info("   Method: Maximum Sharpe Ratio")
    logger.info("   Risk Profile: Moderate")
    
    optimizer = PortfolioOptimizer(
        returns=returns,
        symbols=symbols,
        risk_profile=RiskProfile.MODERATE
    )
    
    opt_result = optimizer.maximum_sharpe_portfolio()
    
    logger.info(f"\n   Optimization Results:")
    logger.info(f"   Expected Return: {opt_result.expected_return * 100:.2f}%")
    logger.info(f"   Volatility: {opt_result.volatility * 100:.2f}%")
    logger.info(f"   Sharpe Ratio: {opt_result.sharpe_ratio:.2f}")
    logger.info(f"   Diversification Ratio: {opt_result.diversification_ratio:.2f}")
    logger.info(f"\n   Optimal Weights:")
    for symbol, weight in opt_result.weights.items():
        logger.info(f"   {symbol}: {weight * 100:.1f}%")
    
    # Test 2: Efficient Frontier
    logger.info("\n3. Calculating Efficient Frontier...")
    frontier_results = optimizer.efficient_frontier(num_points=10)
    
    logger.info(f"   Generated {len(frontier_results)} frontier points")
    logger.info(f"   Return range: {frontier_results[0].expected_return * 100:.2f}% to {frontier_results[-1].expected_return * 100:.2f}%")
    logger.info(f"   Risk range: {frontier_results[0].volatility * 100:.2f}% to {frontier_results[-1].volatility * 100:.2f}%")
    
    # Test 3: Decision Engine (Template Mode)
    logger.info("\n4. Generating Trading Recommendations (Template Mode)...")
    
    anomalies = dict.fromkeys(symbols, False)
    anomalies["BNA"] = True  # Simulate anomaly
    
    engine = DecisionEngine(
        risk_profile=RiskProfile.MODERATE,
        use_llm_explanation=False
    )
    
    recommendations = engine.generate_recommendations(
        symbols=symbols,
        returns=returns,
        market_returns=market_returns,
        current_weights={},
        anomalies=anomalies
    )
    
    logger.info(f"\n   Generated {len(recommendations)} recommendations:")
    for rec in recommendations[:5]:
        logger.info(f"\n   {rec['symbol']}: {rec['action']} (Confidence: {rec['confidence']:.0f}%)")
        logger.info(f"   Expected Return: {rec['expected_return']:.1f}%")
        logger.info(f"   Beta: {rec['beta']:.2f}")
        logger.info(f"   Target Weight: {rec['target_weight'] * 100:.1f}%")
        logger.info(f"   Risk Contribution: {rec['risk_contribution']:.1f}%")
        logger.info(f"   Anomaly: {'YES' if rec['anomaly_detected'] else 'NO'}")
        logger.info(f"   Explanation: {rec['explanation']}")
    
    # Test 4: Decision Engine with LLM Config (simulated)
    logger.info("\n5. Testing LLM Configuration (Dry Run)...")
    
    llm_config = LLMConfig(
        provider="openai",
        model="gpt-3.5-turbo",
        api_key="test_key_not_real",
        temperature=0.3,
        max_tokens=150
    )
    
    logger.info(f"   LLM Config:")
    logger.info(f"   Provider: {llm_config.provider}")
    logger.info(f"   Model: {llm_config.model}")
    logger.info(f"   Temperature: {llm_config.temperature}")
    logger.info(f"   Max Tokens: {llm_config.max_tokens}")
    logger.info(f"   ‚úì LLM configuration structure validated")
    
    # Summary
    logger.info("\n" + "=" * 70)
    logger.info("INTEGRATION TEST SUMMARY")
    logger.info("=" * 70)
    logger.info("‚úì Portfolio optimization: SUCCESS")
    logger.info("‚úì Efficient frontier calculation: SUCCESS")
    logger.info("‚úì Decision engine (template mode): SUCCESS")
    logger.info("‚úì LLM configuration structure: VALID")
    logger.info("‚úì All components wired correctly")
    logger.info("\n‚úÖ INTEGRATION TEST PASSED")
    logger.info("=" * 70)
    
    return True


async def test_database_service_structure():
    """Test database service structure (without actual DB connection)."""
    
    logger.info("\n" + "=" * 70)
    logger.info("Database Service Structure Test")
    logger.info("=" * 70)
    
    from app.ai.data_service import PortfolioDataService
    
    service = PortfolioDataService()
    
    logger.info("\n‚úì PortfolioDataService instantiated")
    logger.info("‚úì Methods available:")
    logger.info("  - fetch_historical_returns")
    logger.info("  - fetch_market_returns")
    logger.info("  - fetch_anomaly_status")
    logger.info("  - fetch_current_weights")
    logger.info("  - fetch_latest_predictions")
    logger.info("  - fetch_sentiment_scores")
    logger.info("  - save_recommendations")
    
    logger.info("\n‚úÖ DATABASE SERVICE STRUCTURE VALID")
    logger.info("=" * 70)


async def main():
    """Run all integration tests."""
    
    try:
        await test_optimization_pipeline()
        await test_database_service_structure()
        
        logger.info("\nüéâ ALL INTEGRATION TESTS PASSED üéâ\n")
        logger.info("Next steps:")
        logger.info("1. Set up database connection in settings")
        logger.info("2. Run: python -m uvicorn app.main:app --reload")
        logger.info("3. Test API: POST /api/v1/ai/portfolio/recommendations/detailed")
        logger.info("4. Check docs: http://localhost:8000/docs")
        
    except Exception as e:
        logger.error(f"\n‚ùå INTEGRATION TEST FAILED: {e}", exc_info=True)
        raise


if __name__ == "__main__":
    asyncio.run(main())
